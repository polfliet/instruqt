slug: kubernetes-new-relic-university
id: dyjhnodiwxxz
type: track
title: Kubernetes - New Relic University
teaser: Learn how to get full observability in a Kubernetes environment with New Relic
description: |
  # New Relic - Observability for Kubernetes TEST

  During this tutorial, we will learn how to get full visibility into a Kubernetes cluster following New Relic's Observability maturity model:

  ![Kubernetes maturity model](https://github.com/polfliet/instruqt/blob/master/kubernetes-new-relic-university/screenshots/maturity-model.png?raw=true "Kubernetes maturity model")

  We will go through the following steps:

  ## Overall Kubernetes Health & Capacity

  * Using Kubernetes secrets

  * **kube-state-metrics** for overall health state of each Kubernetes object

  * Using DaemonSets

  * Controlling cluster capacity with resource requests & resource limits

  ## Dynamic cluster behavior

  * Understanding the Kubernetes API server

  * Using Kubernetes health checks

  * Track important **Kubernetes events** with the **New Relic Kubernetes events integration**

  ## Microservices performance
  * Introduction to Distributed Tracing
  * Correlating application performance data in the context of Kubernetes

  ## Log correlation
  * Introduction to log forwarding with Fluent Bit
  * Capture **Kubernetes logs** from your pods with New Relic's Fluent Bit plugin

  ## Complete service observability
  * Introduction to the Prometheus OpenMetrics format
  * Install the New Relic **Prometheus** integration to get any Prometheus data
  * Using New Relic service integrations
icon: https://storage.googleapis.com/instruqt-frontend/img/tracks/kubernetes.png
tags:
- kubernetes
owner: newrelic
developers:
- svandamme@newrelic.com
- lhurrell@newrelic.com
- spolfliet@newrelic.com
private: false
published: false
challenges:
- slug: kubernetes-secrets
  id: sua74knxvnml
  type: challenge
  title: Best Practice - Using Kubernetes secrets
  teaser: Use a Kubernetes secret to store the New Relic license key
  assignment: "Kubernetes secrets are a great way to store passwords, private keys,
    and other sensitive information. The secrets can then be shared with pods and
    containers without having to pass them plaintext in your YAML files. You can find
    more information about them on the [Kubernetes docs](https://kubernetes.io/docs/concepts/configuration/secret/).\n\nWe
    now will create a Kubernetes secret that contains our New Relic License key. The
    License key will be used by the New Relic Monitoring agents to send back data
    the platform. \n\n### Get your New Relic license key\nFirst we need to retrieve
    your New Relic license key by logging in to your New Relic account, and clicking
    on Account Settings. \n\nIf you don't have an account yet you can create a free
    account on [New Relic.com](https://newrelic.com/signup). Please use your personal
    e-mail address when possible.\n\n![alt text](https://github.com/polfliet/instruqt/blob/master/kubernetes-new-relic-university/screenshots/nrlicense.gif?raw=true
    \"License key\")\n\n### Create the Kubernetes secret\nNext we are going to create
    the Kubernetes secret by copying the following line and **putting your license
    key between the quotes** before pressing enter.\n\n`kubectl create secret generic
    newrelic-secret --from-literal=new_relic_license_key='<YOUR_NEW_RELIC_LICENSE_KEY>'`\n\nYou
    can check if the secret was added succesfully by running `kubectl describe secret
    newrelic-secret`\n\nIf you made a mistake, you can delete the secret with `kubectl
    delete secret newrelic-secret`\n\nThe yaml files in the rest of this tutorial
    will refer to this *newrelic-secret* to retrieve the license key. \n"
  notes:
  - type: text
    contents: Please wait while we set-up your testing environment
  - type: text
    contents: 'Kubernetes (“koo-burr-NET-eez”) is the mangled conventional pronunciation
      of a Greek word, κυβερνήτης, meaning “helmsman” or “pilot.” '
  tabs:
  - title: Shell
    type: terminal
    hostname: kubernetes
  - title: New Relic One
    type: website
    hostname: kubernetes
    url: https://one.newrelic.com
  difficulty: basic
  timelimit: 500
- slug: k8s-health
  id: pej6glwikazf
  type: challenge
  title: Kubernetes health with kube-state-metrics
  teaser: Deploy kube-state-metrics
  assignment: "During this step we will install [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics),
    a service that exposes metrics about the various Kubernetes objects. These metrics
    can then be picked up by monitoring agents to provide information on the health
    and performance of your Kubernetes cluster. \n\n### Installing kube-state-metrics\n\nDownload
    kube-state-metrics version 1.7.2 from Github\n`curl -L -o kube-state-metrics-1.7.2.zip
    https://github.com/kubernetes/kube-state-metrics/archive/v1.7.2.zip && unzip kube-state-metrics-1.7.2.zip`\n\nInstall
    kube-state-metrics in the cluster\n`kubectl apply -f kube-state-metrics-1.7.2/kubernetes`\n\nConfirm
    that kube-state-metrics is installed\n`kubectl get pods --all-namespaces | grep
    kube-state-metrics`\n\nAfter a minute, you should see something like:\n![alt text](https://github.com/polfliet/instruqt/blob/master/kubernetes-new-relic-university/screenshots/ksm.png?raw=true
    \"Kube-state-metrics\")\n\n### Looking at the data\n\nTo take a sneak peak at
    the data that's being retrieve by kube-state-metrics you can run the following
    script to retrieve the IP address of the pod.\n\n`./get-metrics-ip.sh`\n\nYou
    can then use this IP address with `curl` to view the statistics.\n\n`curl http://[IP
    ADDRESS]:8080/metrics`\n\nThe metrics format is based off the Prometheus standard,
    which we will cover later in the workshop. "
  tabs:
  - title: Shell
    type: terminal
    hostname: kubernetes
  difficulty: basic
  timelimit: 500
- slug: nr-k8s-integration
  id: awzvrxxbxqcx
  type: challenge
  title: New Relic Kubernetes integration
  teaser: Deploy the New Relic Kubernetes integration
  assignment: |-
    During this step we will deploy the New Relic Kubernetes integration to our cluster.

    To achieve this we are going to deploy a DaemonSet into our Kubernetes cluster. A DaemonSet is a Kubernetes concept that ensures that we have 1 pod running on each node in our environment. For more information [check out the Kubernetes documentation](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/).

    This DaemonSet will ensure that we have the New Relic Kubernetes agent running on each node of our cluster.
    The yaml file required is already available on our machines, execute the following command to create the New Relic DaemonSet:
    `kubectl create -f nri-k8s.yaml`

    Confirm the DaemonSet was created: `kubectl get daemonsets`

    You should see something like:
    ![Daemon set](https://github.com/polfliet/katacoda-scenarios/blob/master/kubernetes/screenshots/daemonset.png?raw=true "Daemon set")

    Confirm that the agent is running: `kubectl get pods`

    After a minute, you should see something like:
    ![New Relic pod running](https://github.com/polfliet/katacoda-scenarios/blob/master/kubernetes/screenshots/infrapod.png?raw=true "New Relic pod running")

    You can also check the logs of the agent `kubectl logs [POD NAME]` as it's a good place to check for errors and any other issues.
  tabs:
  - title: Shell
    type: terminal
    hostname: kubernetes
  difficulty: basic
  timelimit: 500
- slug: k8s-resources
  id: wwjsy00kdtnb
  type: challenge
  title: Best Practice - Using resource requests & resource limits
  teaser: Control capacity in your cluster
  assignment: "When you deploy a container with K8S it will be automatically scheduled
    on a node with available capacity. This provides a unique challenge as you don't
    know where your container will end up. \n\nImagine you have a container that's
    very memory intensive and it gets deployed on a node with a limited amount of
    available memory. Within minutes your container will put the node under stress,
    and K8S will automatically start removing pods to keep the node stable.\n\nAnother
    scenario is where a container on a node start consuming all of the CPU. All of
    a sudden the other container on that node will start slowing down because they
    need to wait on resources to become available.\n\nTo avoid these scenarios you
    can set resource requests and limits on K8S containers. A container resource requests
    makes sure that there are enough resources available on nodes before they get
    scheduled. A container limit limits the amount of CPU and memory a container uses.
    CPU is hard limit, meaning the container can't use more than the limit amount
    of CPU. Memory behaves differently as K8S will kill the pod when the container
    uses more than the limit of memory.\n\nAn example config is available in the `Editor`
    tab. Open the file `worker.yaml` and look for the following configuration parameters:\n\n```\nresources:\n
    \   requests:\n        cpu: 50m\n        memory: 100Mi\n    limits:\n        cpu:
    200m\n        memory: 300Mi\n```\n\nAs a challenge try adding resource requests
    and limits to the RabbitMQ pod that's running in this environment. The config
    file is available under the `Editor` tab in the file `rabbitmq.yaml`.\n\nYou can
    apply the changes with `kubectl apply app/rabbitmq.yaml` and check if the resources
    are set with ...\n"
  tabs:
  - title: Editor
    type: code
    hostname: kubernetes
    path: /root/app/
  - title: Shell
    type: terminal
    hostname: kubernetes
  difficulty: basic
  timelimit: 500
- slug: nr-k8s-events
  id: 7nr0loh01gfc
  type: challenge
  title: New Relic Kubernetes Events integration
  teaser: Correlate Kubernetes events in the Kubernetes cluster explorer
  assignment: |
    During this step we will deploy the New Relic Kubernetes events integration to our cluster. It will gives us an insight into which actions Kubernetes is performing and which problems are currently active.

    ### Install the New Relic Kubernetes events integration
    The yaml file is already available on our machine, we can apply it:
    `kubectl apply -f nri-kube-events-0.0.2.yaml`

    Confirm the Pod is running
    `kubectl get pods`

    You should see something like:
    ![alt text](https://github.com/polfliet/instruqt/blob/master/kubernetes-new-relic-university/screenshots/eventpod.png?raw=true "Event pod")

    You can also check the logs of the agent `kubectl logs [POD NAME]` as it's a good place to check for errors and any other issues.
  tabs:
  - title: Shell
    type: terminal
    hostname: kubernetes
  difficulty: basic
  timelimit: 500
- slug: nr-distributed-tracing
  id: a6skqehthnpj
  type: challenge
  title: Using Distributed Tracing
  teaser: Trace your microservices
  assignment: |
    Explain DT, spans, etc.

    Refer to DT in k8s cluster explorer

    set a custom attribute?
  difficulty: basic
  timelimit: 500
- slug: nr-logs
  id: j4yyvxmu0etv
  type: challenge
  title: New Relic Logs for Kubernetes
  teaser: Stream Kubernetes logs to New Relic
  assignment: |2-

    New Relic's FluentBit plugin allows us to collect log files generated by the containers in our cluster

    ### Install FluentBit and the New Relic FluentBit plugin
    The yaml files are already available on our machine, we can apply it:

    `kubectl apply -f rbac.yml -f fluent-conf.yml -f new-relic-fluent-plugin.yml`

    Confirm that FluentBit is running
    `kubectl get pods`

    You should see something like:
    ![FluentBit plugin](https://github.com/polfliet/instruqt/blob/master/kubernetes-new-relic-university/screenshots/fluentbit.png?raw=true "New Relic FluentBit plugin")
  difficulty: basic
  timelimit: 500
- slug: nr-prometheus
  id: ycxo28jhzbaz
  type: challenge
  title: New Relic Prometheus OpenMetrics integration
  teaser: Getting Prometheus data
  assignment: |2-

    The New Relic Prometheus OpenMetrics integration allows us to scrape any endpoint in our cluster.

    ### Install the New Relic Prometheus OpenMetrics integration
    The yaml file is already on the machine.
    `kubectl apply -f nri-prometheus-latest.yaml`

    Confirm that the deployment has been created:
    `kubectl get deployments nri-prometheus`

    You should see something like:
    ![Prometheus integration](https://github.com/polfliet/instruqt/blob/master/kubernetes-new-relic-university/screenshots/prometheus.png?raw=true "Prometheus integration")
  difficulty: basic
  timelimit: 500
- slug: nr-integrations
  id: 0wlvfllrfpri
  type: challenge
  title: New Relic service integrations
  teaser: Use New Relic's Kubernetes service integrations
  assignment: TODO use our OKIs
  difficulty: basic
  timelimit: 500
- slug: nr-melt
  id: dc5snwqaxpw0
  type: challenge
  title: Building a M.E.L.T. dashboard
  teaser: Connecting Metrics, Events, Logs and Traces
  assignment: TODO
  difficulty: basic
  timelimit: 500
checksum: "1638530219596719971"
